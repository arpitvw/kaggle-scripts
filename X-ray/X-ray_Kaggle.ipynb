{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil as shu\n",
    "import torchvision.datasets as ds\n",
    "import torchvision.transforms as tt\n",
    "import torch.utils.data as tud\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pic_labels=pd.read_csv('F:/Kaggle_version2/bronchitis_detection/train_labels/Train_Labels.csv')\n",
    "file_names=pic_labels[pic_labels['Labels']==0]['Images'].values\n",
    "\n",
    "for i in os.listdir('F:/Kaggle_version2/bronchitis_detection/Train_Images'):\n",
    "    if i.endswith ('.png'):\n",
    "        if i[:-4] in file_names:\n",
    "            shu.move(os.path.join(source_path,i),'F:/Kaggle_version2/bronchitis_detection/Train_Images/0')\n",
    "            \n",
    "        elif i[:-4] in file_names:\n",
    "            shu.move(os.path.join(source_path,i),'F:/Kaggle_version2/bronchitis_detection/Train_Images/1')\n",
    "           \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize = tt.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "transforms=tt.Compose([tt.Resize(1000),\n",
    "                               tt.CenterCrop(224),\n",
    "                               tt.ToTensor(),\n",
    "                               normalize])\n",
    "data_folder=ds.ImageFolder('F:/Kaggle_version2/bronchitis_detection/Train_Images',transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader=tud.DataLoader(data_folder,batch_size=20,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(dataloader))\n",
    "#print (labels)\n",
    "inputs, labels = Variable(inputs), Variable(labels)\n",
    "#print (labels)\n",
    "\n",
    "# for i, (images, labels) in enumerate(data_folder):\n",
    "#     images = Variable(images)\n",
    "#     labels = Variable(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = resnet(inputs)\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'train': len(dataloders['train'].dataset)}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                \n",
    "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} '.format(epoch, num_epochs - 1,train_epoch_loss, train_epoch_acc))\n",
    "            \n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 2 classes\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs,50)\n",
    "# resnet.fc = torch.nn.Linear(num_ftrs,25)\n",
    "resnet.fc = torch.nn.Linear(num_ftrs,10)\n",
    "resnet.fc = torch.nn.Linear(num_ftrs,3)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "dloaders = {'train':dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/99] train loss: 0.0391 acc: 0.4531 \n",
      "Epoch [1/99] train loss: 0.0356 acc: 0.5078 \n",
      "Epoch [2/99] train loss: 0.0346 acc: 0.5578 \n",
      "Epoch [3/99] train loss: 0.0354 acc: 0.5641 \n",
      "Epoch [4/99] train loss: 0.0332 acc: 0.5859 \n",
      "Epoch [5/99] train loss: 0.0334 acc: 0.5922 \n",
      "Epoch [6/99] train loss: 0.0323 acc: 0.6266 \n",
      "Epoch [7/99] train loss: 0.0315 acc: 0.6562 \n",
      "Epoch [8/99] train loss: 0.0306 acc: 0.6672 \n",
      "Epoch [9/99] train loss: 0.0307 acc: 0.6578 \n",
      "Epoch [10/99] train loss: 0.0300 acc: 0.7000 \n",
      "Epoch [11/99] train loss: 0.0309 acc: 0.6547 \n",
      "Epoch [12/99] train loss: 0.0302 acc: 0.6875 \n",
      "Epoch [13/99] train loss: 0.0302 acc: 0.6906 \n",
      "Epoch [14/99] train loss: 0.0301 acc: 0.7016 \n",
      "Epoch [15/99] train loss: 0.0298 acc: 0.7125 \n",
      "Epoch [16/99] train loss: 0.0303 acc: 0.6953 \n",
      "Epoch [17/99] train loss: 0.0304 acc: 0.7078 \n",
      "Epoch [18/99] train loss: 0.0308 acc: 0.6609 \n",
      "Epoch [19/99] train loss: 0.0299 acc: 0.7141 \n",
      "Epoch [20/99] train loss: 0.0302 acc: 0.7125 \n",
      "Epoch [21/99] train loss: 0.0304 acc: 0.7094 \n",
      "Epoch [22/99] train loss: 0.0303 acc: 0.6828 \n",
      "Epoch [23/99] train loss: 0.0304 acc: 0.6813 \n",
      "Epoch [24/99] train loss: 0.0301 acc: 0.6922 \n",
      "Epoch [25/99] train loss: 0.0304 acc: 0.7063 \n",
      "Epoch [26/99] train loss: 0.0304 acc: 0.6844 \n",
      "Epoch [27/99] train loss: 0.0305 acc: 0.6797 \n",
      "Epoch [28/99] train loss: 0.0305 acc: 0.6859 \n",
      "Epoch [29/99] train loss: 0.0304 acc: 0.7000 \n",
      "Epoch [30/99] train loss: 0.0302 acc: 0.7047 \n",
      "Epoch [31/99] train loss: 0.0301 acc: 0.7078 \n",
      "Epoch [32/99] train loss: 0.0299 acc: 0.6984 \n",
      "Epoch [33/99] train loss: 0.0304 acc: 0.6781 \n",
      "Epoch [34/99] train loss: 0.0298 acc: 0.7141 \n",
      "Epoch [35/99] train loss: 0.0301 acc: 0.6922 \n",
      "Epoch [36/99] train loss: 0.0303 acc: 0.7016 \n",
      "Epoch [37/99] train loss: 0.0298 acc: 0.7125 \n",
      "Epoch [38/99] train loss: 0.0308 acc: 0.6797 \n",
      "Epoch [39/99] train loss: 0.0307 acc: 0.6859 \n",
      "Epoch [40/99] train loss: 0.0303 acc: 0.6969 \n",
      "Epoch [41/99] train loss: 0.0302 acc: 0.6937 \n",
      "Epoch [42/99] train loss: 0.0302 acc: 0.6922 \n",
      "Epoch [43/99] train loss: 0.0303 acc: 0.6891 \n",
      "Epoch [44/99] train loss: 0.0301 acc: 0.6984 \n",
      "Epoch [45/99] train loss: 0.0307 acc: 0.6781 \n",
      "Epoch [46/99] train loss: 0.0302 acc: 0.7047 \n",
      "Epoch [47/99] train loss: 0.0299 acc: 0.7047 \n",
      "Epoch [48/99] train loss: 0.0304 acc: 0.6953 \n",
      "Epoch [49/99] train loss: 0.0303 acc: 0.6828 \n",
      "Epoch [50/99] train loss: 0.0301 acc: 0.7094 \n",
      "Epoch [51/99] train loss: 0.0299 acc: 0.7094 \n",
      "Epoch [52/99] train loss: 0.0305 acc: 0.6937 \n",
      "Epoch [53/99] train loss: 0.0302 acc: 0.6750 \n",
      "Epoch [54/99] train loss: 0.0302 acc: 0.7047 \n",
      "Epoch [55/99] train loss: 0.0304 acc: 0.6797 \n",
      "Epoch [56/99] train loss: 0.0303 acc: 0.7063 \n",
      "Epoch [57/99] train loss: 0.0301 acc: 0.7016 \n",
      "Epoch [58/99] train loss: 0.0300 acc: 0.7188 \n",
      "Epoch [59/99] train loss: 0.0305 acc: 0.6828 \n",
      "Epoch [60/99] train loss: 0.0303 acc: 0.6906 \n",
      "Epoch [61/99] train loss: 0.0303 acc: 0.6813 \n",
      "Epoch [62/99] train loss: 0.0299 acc: 0.7250 \n",
      "Epoch [63/99] train loss: 0.0300 acc: 0.7000 \n",
      "Epoch [64/99] train loss: 0.0303 acc: 0.6906 \n",
      "Epoch [65/99] train loss: 0.0302 acc: 0.7016 \n",
      "Epoch [66/99] train loss: 0.0300 acc: 0.7266 \n",
      "Epoch [67/99] train loss: 0.0305 acc: 0.6859 \n",
      "Epoch [68/99] train loss: 0.0301 acc: 0.6969 \n",
      "Epoch [69/99] train loss: 0.0303 acc: 0.6844 \n",
      "Epoch [70/99] train loss: 0.0304 acc: 0.6766 \n",
      "Epoch [71/99] train loss: 0.0303 acc: 0.7000 \n",
      "Epoch [72/99] train loss: 0.0298 acc: 0.7188 \n",
      "Epoch [73/99] train loss: 0.0302 acc: 0.6891 \n",
      "Epoch [74/99] train loss: 0.0304 acc: 0.6734 \n",
      "Epoch [75/99] train loss: 0.0302 acc: 0.7047 \n",
      "Epoch [76/99] train loss: 0.0299 acc: 0.6844 \n",
      "Epoch [77/99] train loss: 0.0301 acc: 0.6984 \n",
      "Epoch [78/99] train loss: 0.0304 acc: 0.6797 \n",
      "Epoch [79/99] train loss: 0.0298 acc: 0.7219 \n",
      "Epoch [80/99] train loss: 0.0301 acc: 0.6922 \n",
      "Epoch [81/99] train loss: 0.0300 acc: 0.7141 \n",
      "Epoch [82/99] train loss: 0.0300 acc: 0.7156 \n",
      "Epoch [83/99] train loss: 0.0301 acc: 0.7156 \n",
      "Epoch [84/99] train loss: 0.0305 acc: 0.6922 \n",
      "Epoch [85/99] train loss: 0.0301 acc: 0.6891 \n",
      "Epoch [86/99] train loss: 0.0304 acc: 0.7000 \n",
      "Epoch [87/99] train loss: 0.0301 acc: 0.6953 \n",
      "Epoch [88/99] train loss: 0.0302 acc: 0.7109 \n",
      "Epoch [89/99] train loss: 0.0298 acc: 0.7156 \n",
      "Epoch [90/99] train loss: 0.0301 acc: 0.7125 \n",
      "Epoch [91/99] train loss: 0.0303 acc: 0.7094 \n",
      "Epoch [92/99] train loss: 0.0301 acc: 0.6984 \n",
      "Epoch [93/99] train loss: 0.0301 acc: 0.7016 \n",
      "Epoch [94/99] train loss: 0.0302 acc: 0.7047 \n",
      "Epoch [95/99] train loss: 0.0300 acc: 0.7047 \n",
      "Epoch [96/99] train loss: 0.0304 acc: 0.6813 \n",
      "Epoch [97/99] train loss: 0.0302 acc: 0.6750 \n",
      "Epoch [98/99] train loss: 0.0303 acc: 0.7141 \n",
      "Epoch [99/99] train loss: 0.0301 acc: 0.6797 \n",
      "Best val Acc: 0.000000\n",
      "Training time: 1440.318974 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = train_model(dloaders, resnet, criterion, optimizer, exp_lr_scheduler, num_epochs=100)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloaders = {'train':dataloader}\n",
    "dataset_sizes = {'train': len(dloaders['train'].dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 640}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = tt.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "transforms=tt.Compose([tt.Resize(1000),\n",
    "                               tt.CenterCrop(224),\n",
    "                               tt.ToTensor(),\n",
    "                               normalize])\n",
    "data_folder=ds.ImageFolder('F:/Kaggle_version2/bronchitis_detection/test/',transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader=tud.DataLoader(data_folder,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inputs,labels in dataloader:\n",
    "    #print (inputs)\n",
    "    inputs=Variable(inputs)\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    print (preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=os.listdir('F:/Kaggle_version2/bronchitis_detection/test/Test_Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CR_0001.png',\n",
       " 'CR_0003.png',\n",
       " 'CR_0004.png',\n",
       " 'CR_0020.png',\n",
       " 'CR_0022.png',\n",
       " 'CR_0024.png',\n",
       " 'CR_0026.png',\n",
       " 'CR_0029.png',\n",
       " 'CR_0030.png',\n",
       " 'CR_0034.png',\n",
       " 'CR_0035.png',\n",
       " 'CR_0037.png',\n",
       " 'CR_0041.png',\n",
       " 'CR_0042.png',\n",
       " 'CR_0047.png',\n",
       " 'CR_0052.png',\n",
       " 'CR_0068.png',\n",
       " 'CR_0070.png',\n",
       " 'CR_0071.png',\n",
       " 'CR_0083.png',\n",
       " 'CR_0096.png',\n",
       " 'CR_0100.png',\n",
       " 'CR_0101.png',\n",
       " 'CR_0110.png',\n",
       " 'CR_0111.png',\n",
       " 'CR_0114.png',\n",
       " 'CR_0121.png',\n",
       " 'CR_0126.png',\n",
       " 'CR_0131.png',\n",
       " 'CR_0134.png',\n",
       " 'CR_0137.png',\n",
       " 'CR_0143.png',\n",
       " 'CR_0145.png',\n",
       " 'CR_0146.png',\n",
       " 'CR_0148.png',\n",
       " 'CR_0157.png',\n",
       " 'CR_0159.png',\n",
       " 'CR_0170.png',\n",
       " 'CR_0173.png',\n",
       " 'CR_0177.png',\n",
       " 'CR_0182.png',\n",
       " 'CR_0203.png',\n",
       " 'CR_0208.png',\n",
       " 'CR_0211.png',\n",
       " 'CR_0214.png',\n",
       " 'CR_0216.png',\n",
       " 'CR_0219.png',\n",
       " 'CR_0220.png',\n",
       " 'CR_0233.png',\n",
       " 'CR_0236.png',\n",
       " 'CR_0240.png',\n",
       " 'CR_0245.png',\n",
       " 'CR_0247.png',\n",
       " 'CR_0265.png',\n",
       " 'CR_0266.png',\n",
       " 'CR_0268.png',\n",
       " 'CR_0283.png',\n",
       " 'CR_0300.png',\n",
       " 'CR_0304.png',\n",
       " 'CR_0311.png',\n",
       " 'CR_0313.png',\n",
       " 'CR_0315.png',\n",
       " 'CR_0317.png',\n",
       " 'CR_0318.png',\n",
       " 'CR_0324.png',\n",
       " 'CR_0325.png',\n",
       " 'CR_0326.png',\n",
       " 'CR_0327.png',\n",
       " 'CR_0341.png',\n",
       " 'CR_0348.png',\n",
       " 'CR_0353.png',\n",
       " 'CR_0359.png',\n",
       " 'CR_0365.png',\n",
       " 'CR_0377.png',\n",
       " 'CR_0379.png',\n",
       " 'CR_0382.png',\n",
       " 'CR_0386.png',\n",
       " 'CR_0391.png',\n",
       " 'CR_0392.png',\n",
       " 'CR_0395.png',\n",
       " 'CR_0396.png',\n",
       " 'CR_0397.png',\n",
       " 'CR_0399.png',\n",
       " 'CR_0411.png',\n",
       " 'CR_0421.png',\n",
       " 'CR_0424.png',\n",
       " 'CR_0425.png',\n",
       " 'CR_0427.png',\n",
       " 'CR_0434.png',\n",
       " 'CR_0436.png',\n",
       " 'CR_0447.png',\n",
       " 'CR_0448.png',\n",
       " 'CR_0457.png',\n",
       " 'CR_0458.png',\n",
       " 'CR_0464.png',\n",
       " 'CR_0465.png',\n",
       " 'CR_0471.png',\n",
       " 'CR_0473.png',\n",
       " 'CR_0474.png',\n",
       " 'CR_0476.png',\n",
       " 'CR_0477.png',\n",
       " 'CR_0480.png',\n",
       " 'CR_0482.png',\n",
       " 'CR_0487.png',\n",
       " 'CR_0489.png',\n",
       " 'CR_0490.png',\n",
       " 'CR_0492.png',\n",
       " 'CR_0494.png',\n",
       " 'CR_0495.png',\n",
       " 'CR_0497.png',\n",
       " 'CR_0503.png',\n",
       " 'CR_0504.png',\n",
       " 'CR_0514.png',\n",
       " 'CR_0515.png',\n",
       " 'CR_0522.png',\n",
       " 'CR_0530.png',\n",
       " 'CR_0536.png',\n",
       " 'CR_0547.png',\n",
       " 'CR_0558.png',\n",
       " 'CR_0568.png',\n",
       " 'CR_0571.png',\n",
       " 'CR_0588.png',\n",
       " 'CR_0599.png',\n",
       " 'CR_0600.png',\n",
       " 'CR_0615.png',\n",
       " 'CR_0628.png',\n",
       " 'CR_0634.png',\n",
       " 'CR_0637.png',\n",
       " 'CR_0649.png',\n",
       " 'CR_0662.png',\n",
       " 'MR_0003.png',\n",
       " 'MR_0005.png',\n",
       " 'MR_0013.png',\n",
       " 'MR_0023.png',\n",
       " 'MR_0027.png',\n",
       " 'MR_0040.png',\n",
       " 'MR_0051.png',\n",
       " 'MR_0052.png',\n",
       " 'MR_0054.png',\n",
       " 'MR_0057.png',\n",
       " 'MR_0059.png',\n",
       " 'MR_0070.png',\n",
       " 'MR_0080.png',\n",
       " 'MR_0095.png',\n",
       " 'MR_0101.png',\n",
       " 'MR_0108.png',\n",
       " 'MR_0126.png',\n",
       " 'MR_0140.png',\n",
       " 'MR_0170.png',\n",
       " 'MR_0203.png',\n",
       " 'MR_0228.png',\n",
       " 'MR_0251.png',\n",
       " 'MR_0253.png',\n",
       " 'MR_0275.png',\n",
       " 'MR_0338.png',\n",
       " 'MR_0348.png',\n",
       " 'MR_0352.png',\n",
       " 'MR_0369.png',\n",
       " 'MR_0372.png',\n",
       " 'MR_0383.png']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
