{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The 5 stages include:\n",
    "\n",
    "Normalizing the image prior to description.\n",
    "Computing gradients in both the x and y directions.\n",
    "Obtaining weighted votes in spatial and orientation cells.\n",
    "Contrast normalizing overlapping spatial cells.\n",
    "Collecting all Histograms of Oriented gradients to form the final feature vector.\n",
    "\n",
    "The most important parameters for the HOG descriptor are the orientations , pixels_per_cell , and the cells_per_block\n",
    "\n",
    "HOG descriptors are mainly used to describe the structural shape and appearance of an object in an image,\n",
    "making them excellent descriptors for object classification.\n",
    "However, since HOG captures local intensity gradients and edge directions, it also makes for a good texture descriptor.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Step 1: Normalizing the image prior to description.\n",
    "\n",
    "i)Gamma/power law normalization: In this case, we take the \\log(p) of each pixel p in the input image. However, as Dalal and Triggs demonstrated, this approach is perhaps an “over-correction” and hurts performance.\n",
    "ii)Square-root normalization: Here, we take the \\sqrt(p) of each pixel p in the input image. By definition, square-root normalization compresses the input pixel intensities far less than gamma normalization. And again, as Dalal and Triggs demonstrated, square-root normalization actually increases accuracy rather than hurts it.\n",
    "iii)Variance normalization: A slightly less used form of normalization is variance normalization.\n",
    "Here, we compute both the mean \\mu and standard deviation \\sigma of the input image.\n",
    "All pixels are mean centered by subtracting the mean from the pixel intensity,\n",
    "and then normalized through dividing by the standard deviation: p' = (p - \\mu) / \\sigma. \n",
    "Dalal and Triggs do not report accuracy on variance normalization; \n",
    "however, it is a form of normalization that I like to perform and thought it was worth including.\n",
    "\n",
    "\n",
    "Step 2: Gradient computation\n",
    "\n",
    "The first actual step in the HOG descriptor is to compute the image gradient in both the x and y direction. These calculations should seem familiar, as we have already reviewed them in the Gradients lesson.\n",
    "\n",
    "We’ll apply a convolution operation to obtain the gradient images:\n",
    "\n",
    "G_{x} = I \\star D_{x} and G_{y} = I \\star D_{y}\n",
    "where I is the input image, D_{x} is our filter in the x-direction, and D_{y} is our filter in the y-direction.\n",
    "\n",
    "Now that we have our gradient images, we can compute the final gradient magnitude representation of the image:\n",
    "|G| = \\sqrt{G_{x}^{2} + G_{y}^{2}}\n",
    "\n",
    "Finally, the orientation of the gradient for each pixel in the input image can then be computed by:\n",
    "\n",
    "\\theta = arctan2(G_{y}, G_{x})\n",
    "\n",
    "\n",
    "The number of orientations  control the number of bins in the resulting histogram. \n",
    "The gradient angle is either within the range [0, 180] (unsigned) or [0, 360] (signed).\n",
    "In general, it’s preferable to use unsigned gradients in the range [0, 180] with orientations  somewhere in the range [9, 12].\n",
    "But depending on your application, using signed gradients over unsigned gradients can improve accuracy.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset prepration \n",
    "different folder with logos  so that folder name will go as label and images as dataset\n",
    "for imagePath in paths.list_images(args[\"training\"]):\n",
    "    # extract the make of the car\n",
    "    make = imagePath.split(\"/\")[-2]\n",
    "make will be the label for the image\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "image = cv2.imread(r'C:\\Users\\arpit14276\\Desktop\\pyimagesearch\\hog_car_logos.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edged = imutils.auto_canny(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts=cv2.findContours(gray.copy(),cv2.RETR_TREE ,cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cnts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.zeros(gray.shape,dtype='uint8')\n",
    "for i in cnts[1]:\n",
    "    \n",
    "    x,y,w,h= cv2.boundingRect(i)\n",
    "    logo = gray[y:y + h, x:x + w]\n",
    "    logo = cv2.resize(logo, (200, 100))\n",
    "    (H,hogimage) = feature.hog(logo, orientations=9, pixels_per_cell=(10, 10),cells_per_block=(2, 2),visualise=True, transform_sqrt=True, block_norm=\"L1\")\n",
    "    \n",
    "hogimage = exposure.rescale_intensity(hogimage, out_range=(0, 255))# for visualitsation \n",
    "hogimage = hogimage.astype(\"uint8\")\n",
    "cv2.imshow('mask',hogimage)\n",
    "cv2.imshow('image',gray)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in cnts[1]:\n",
    "    a.append( cv2.contourArea(i))\n",
    "cv2.drawContours(mask.copy(),[cnts[1][np.argmax(a)]],-1,255,-1)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "gokarna=cv2.imread(r'C:\\Users\\arpit14276\\Downloads\\IMG_3063.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "go=cv2.resize(gokarna, (4000, 2667))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('go',go)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('gokarana.jpg',go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid, sys\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_blob_service = BlockBlobService(account_name='azureblobstorage2018', account_key='KqVunuP6PRz46AbThrCQjy6YEFYgyhLLAjAbpwJFSnLHmTTpI4eR5RqjdMQFFEiSq1XnL+saQ6MwMsCqnzBTmQ==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_name ='datailes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = block_blob_service.list_blobs(container_name)\n",
    "for blob in generator:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chmod(r'C:\\Users\\arpit14276\\Desktop\\pyimagesearch\\shirts',777)\n",
    "block_blob_service.get_blob_to_path(container_name, 'GP_ZZZPublic_FY2018-19_M06.csv', r'C:\\Users\\arpit14276\\Desktop\\pyimagesearch\\shirts\\c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_blob_service.create_blob_from_path(container_name, 'PS_20174392719_1491204439457_log.csv', r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\PS_20174392719_1491204439457_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "filepath=r'C:\\Users\\arpit14276\\Desktop\\pyimagesearch\\shirts'\n",
    "generator = block_blob_service.list_blobs(container_name)\n",
    "for i,blob in enumerate(generator):\n",
    "    if blob.name.endswith('.py':)\n",
    "        block_blob_service.create_blob_from_path(container_name, blob.name, r'D:\\home\\site\\wwwroot\\NHS_test\\DQ_azure.py')\n",
    "    path=filepath + '\\{}'.format(blob.name)\n",
    "    block_blob_service.get_blob_to_path(container_name, blob.name,path)\n",
    "    call([\"python\", r\"C:\\Users\\arpit14276\\Desktop\\facerecognization\\DQ.py\",r'file={}'.format(path)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "\n",
    "call([\"python\", r\"C:\\Users\\arpit14276\\Desktop\\facerecognization\\DQ.py\",r'file=C:\\Users\\arpit14276\\Desktop\\facerecognization\\PS_20174392719_1491204439457_log.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url=\"https://azureblobstorage2018.blob.core.windows.net/datailes/PS_20174392719_1491204439457_log.csv\"\n",
    "s=requests.get(url).content\n",
    "c=pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(a):\n",
    "    return(str(type(a)))\n",
    "b=[]\n",
    "check={}\n",
    "#check=to\n",
    "csv=pd.read_csv(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\test.txt')\n",
    "for i in csv.columns:\n",
    "    c_name=i+'_error'\n",
    "    check[c_name]=csv[i].apply(lambda a:   if test(a)!=\"<class 'int'>\" else None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "b=[]\n",
    "csv=pd.read_csv(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\PS_20174392719_1491204439457_log.csv')\n",
    "#print (pd.io.sql.get_schema(csv.reset_index(),'csv',flavor='mysql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_blob_service.make_blob_url(container_name, 'PS_20174392719_1491204439457_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sql\n",
    "print (sql.get_schema(csv,'test','mysql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "pd.read_csv(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\PS_20174392719_1491204439457_log.csv')\n",
    "print (time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\PS_20174392719_1491204439457_log\\PS_20174392719_1491204439457_log.sql','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path=r'C:\\Users\\arpit14276\\Desktop\\facerecognization'\n",
    "def sorted_ls(paths):\n",
    "    mtime = lambda f: os.stat(os.path.join(paths, f)).st_mtime\n",
    "    return list(sorted(os.listdir(paths), key=mtime,reverse=True))[0]\n",
    "print(sorted_ls(r'C:\\Users\\arpit14276\\Desktop\\facerecognization'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent container test1\n",
      "previous container test\n",
      "dolumn_difference []\n",
      "data_value difference {'nameDest': 'current value 10 , actual value 11'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import requests\n",
    "import os, uuid, sys\n",
    "import chardet\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "\n",
    "def find_encoding(fname):\n",
    "    #r_file = open(fname, 'rb').read()\n",
    "    result = chardet.detect(fname)\n",
    "    charenc = result['encoding']\n",
    "    return charenc\n",
    "#enco=find_encoding(file_name)\n",
    "\n",
    "\n",
    "account_name='azureblobstorage2018'\n",
    "account_key='KqVunuP6PRz46AbThrCQjy6YEFYgyhLLAjAbpwJFSnLHmTTpI4eR5RqjdMQFFEiSq1XnL+saQ6MwMsCqnzBTmQ=='\n",
    "block_blob_service = BlockBlobService(account_name=account_name, account_key=account_key)\n",
    "\n",
    "'''name=[]\n",
    "time_stamp=[]\n",
    "for i in block_blob_service.list_containers():\n",
    "    #print (i)\n",
    "    #print (i.properties.last_modified)\n",
    "    name.append(i.name)\n",
    "    time_stamp.append(i.properties.last_modified)\n",
    "\n",
    "container_names=zip(name,time_stamp)\n",
    "#g=sorted(container_names)[0][0]\n",
    "#print (g)\n",
    "\n",
    "def file_extarct(containers):\n",
    "    blob_url={}\n",
    "    for i in [0,1] :\n",
    "        print (containers)\n",
    "        container_name=sorted(containers,reverse=True)[i][0]\n",
    "        print (container_name)\n",
    "        generator = block_blob_service.list_blobs(container_name)\n",
    "        print (generator)\n",
    "        for blob in generator:\n",
    "            print (blob.name)\n",
    "            if blob.name.endswith('DQ.csv'):\n",
    "                DQ_name=blob.name            \n",
    "                blob_url[container_name]=block_blob_service.make_blob_url(container_name,blob.name )\n",
    "        containers=zip(containers)\n",
    "    #print (blob_url)\n",
    "    return blob_url\n",
    "\n",
    "url=file_extarct(container_names)\n",
    "key=url.keys()'''\n",
    "name=[]\n",
    "time_stamp=[]\n",
    "#print (key)\n",
    "for i in block_blob_service.list_containers():\n",
    "    #print (i)\n",
    "    #print (i.properties.last_modified)\n",
    "    name.append(i.name)\n",
    "    time_stamp.append(i.properties.last_modified)\n",
    "\n",
    "container_names=zip(name,time_stamp)\n",
    "recent=sorted(container_names,reverse=True)[0][0]\n",
    "print ('recent container',recent)\n",
    "generator = block_blob_service.list_blobs(recent)\n",
    "#print (generator)\n",
    "recent_DQ_name=''\n",
    "for blob in generator:\n",
    "    #print (blob.name)\n",
    "    if blob.name.endswith('DQ.csv'):\n",
    "        recent_DQ_name=blob.name\n",
    "recent_url=block_blob_service.make_blob_url(recent,recent_DQ_name )\n",
    "previous=sorted(zip(name,time_stamp),reverse=True)[1][0]\n",
    "print ('previous container',previous)\n",
    "generator = block_blob_service.list_blobs(previous)\n",
    "#print (generator)\n",
    "previous_DQ_name=''\n",
    "for blob in generator:\n",
    "    #print (blob.name)\n",
    "    if blob.name.endswith('DQ.csv'):\n",
    "        previous_DQ_name=blob.name\n",
    "previous_url=block_blob_service.make_blob_url(previous,previous_DQ_name )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "current_file=requests.get(recent_url).content\n",
    "previous_file=requests.get(previous_url).content\n",
    "\n",
    "# path=r'C:\\Users\\arpit14276\\Desktop\\facerecognization'\n",
    "\n",
    "# def sorted_ls(paths):\n",
    "#     mtime = lambda f: os.stat(os.path.join(paths, f)).st_mtime\n",
    "#     return sorted(os.listdir(paths), key=mtime,reverse=True)[0]\n",
    "# print (sorted_ls(path))\n",
    "# file_path=path+'\\\\'+sorted_ls(path)\n",
    "\n",
    "\n",
    "# for i in os.listdir(file_path):\n",
    "#     if i.endswith('DQ.csv'):\n",
    "#         files=i\n",
    "\n",
    "DQ=pd.read_csv(io.StringIO(previous_file.decode(find_encoding(previous_file))),encoding = find_encoding(previous_file))\n",
    "DQ_current=pd.read_csv(io.StringIO(current_file.decode(find_encoding(current_file))),encoding = find_encoding(current_file))\n",
    "column=[]\n",
    "value={}\n",
    "previous=DQ.columns\n",
    "current=DQ_current.columns\n",
    "\n",
    "for i in current:\n",
    "    if i in current:\n",
    "        pass\n",
    "    else:\n",
    "        column.append(i)\n",
    "    \n",
    "for i in range(DQ.shape[0]):\n",
    "    if DQ['max_value'][i]<=DQ_current['max_value'][i]:\n",
    "        pass\n",
    "    else:\n",
    "        #value.append(DQ_current['column name'][i])\n",
    "        value[DQ_current['column name'][i]]='current value {} , actual value {}'.format(DQ_current['max_value'][i],DQ['max_value'][i])\n",
    "        \n",
    "  \n",
    "    \n",
    "print ('dolumn_difference',column)\n",
    "print ('data_value difference',value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nameDest': 'current value 10 , actual value 11'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQ_current.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid, sys\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "account_name='azureblobstorage2018'\n",
    "account_key='KqVunuP6PRz46AbThrCQjy6YEFYgyhLLAjAbpwJFSnLHmTTpI4eR5RqjdMQFFEiSq1XnL+saQ6MwMsCqnzBTmQ=='\n",
    "block_blob_service = BlockBlobService(account_name=account_name, account_key=account_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for i in block_blob_service.list_containers():\n",
    "    print (i.properties.last_modified)\n",
    "    a.append(i.name)\n",
    "    b.append(i.properties.last_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=zip(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=sorted(t,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc(f):\n",
    "    print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(t):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import requests\n",
    "import os, uuid, sys\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "\n",
    "def find_encoding(fname):\n",
    "    #r_file = open(fname, 'rb').read()\n",
    "    result = chardet.detect(fname)\n",
    "    charenc = result['encoding']\n",
    "    return charenc\n",
    "#enco=find_encoding(file_name)\n",
    "\n",
    "\n",
    "account_name='azureblobstorage2018'\n",
    "account_key='KqVunuP6PRz46AbThrCQjy6YEFYgyhLLAjAbpwJFSnLHmTTpI4eR5RqjdMQFFEiSq1XnL+saQ6MwMsCqnzBTmQ=='\n",
    "block_blob_service = BlockBlobService(account_name=account_name, account_key=account_key)\n",
    "name=[]\n",
    "time_stamp=[]\n",
    "for i in block_blob_service.list_containers():\n",
    "    #print (i)\n",
    "    #print (i.properties.last_modified)\n",
    "    name.append(i.name)\n",
    "    time_stamp.append(i.properties.last_modified)\n",
    "\n",
    "container_names=zip(name,time_stamp)\n",
    "g=sorted(container_names)[0][0]\n",
    "print (g)\n",
    "\n",
    "\n",
    "for i in [0,1]: \n",
    "    print ('test')\n",
    "    container_name=sorted(container_names)[i][0]\n",
    "    print (container_name)\n",
    "    generator = block_blob_service.list_blobs(container_name)\n",
    "    print (generator)\n",
    "    for blob in generator:\n",
    "            print (blob.name)\n",
    "            if blob.name.endswith('DQ.csv'):\n",
    "                DQ_name=blob.name            \n",
    "                blob_url[container_name]=block_blob_service.make_blob_url(container_name,blob.name )\n",
    "            \n",
    "    #print (blob_url)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
