{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1=cv2.imread(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\dogs\\th7RRHY09L.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2=cv2.imread(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\horse\\Tarpan-myth-152.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 309, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##check \n",
    "i=cv2.split(image)\n",
    "i[0].sum()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50.20801859])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## function to calculate the distance \n",
    "def colordistance(image1,image2):\n",
    "    dis1=cv2.meanStdDev(image1)\n",
    "    dis2=cv2.meanStdDev(image2)\n",
    "    add=[]\n",
    "    for i,j in zip(dis1,dis2):\n",
    "        add.append((i-j)**2)\n",
    "    return np.sqrt(sum(sum(add)))\n",
    "colordistance(image1,image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function using libraries\n",
    "\n",
    "imagepath=sorted(list(paths.list_images(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\horse')))\n",
    "index={}\n",
    "for images in imagepath:\n",
    "    image=cv2.imread(images)\n",
    "    filename=images\n",
    "    (means,stds)=cv2.meanStdDev(image)\n",
    "    features=np.concatenate([means,stds]).flatten()\n",
    "    index[filename]=features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=cv2.imread(r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\horse\\Tarpan-myth-152.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=sorted(index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(keys):\n",
    "    if j==r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\horse\\Tarpan-myth-152.jpg':\n",
    "        continue\n",
    "    im=cv2.imread(j)\n",
    "    d=dis.euclidean(index[r'C:\\Users\\arpit14276\\Desktop\\facerecognization\\horse\\Tarpan-myth-152.jpg'],index[j])\n",
    "    cv2.putText(im,\"%.2f\" % (d),(10,30),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "    cv2.imshow(j,im)\n",
    "cv2.imshow('query',query)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([130.04244824, 142.48868885, 133.06393942,  67.75802596,\n",
       "        57.76058154,  62.7182011 ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "####quiz ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=cv2.imread(r'C:\\Users\\arpit14276\\Desktop\\pyimagesearch\\raptors_02.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "(i,j)=cv2.meanStdDev(quiz)\n",
    "features2=np.concatenate([i,j]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.40508234, 29.97264203, 39.20540541, 27.05237628, 23.14341739,\n",
       "       24.45663121])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.968268349855276"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis.euclidean(features1,features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
